{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestClassification_withBERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJckRL0HepUjaOrGlYvi9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrojaakter/Natural-Language-Processing/blob/main/TestClassification_withBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cde55EgfyYOu"
      },
      "source": [
        "- Load the IMDB dataset\n",
        "- Load a BERT model from TensorFlow Hub\n",
        "- Build a new model by combining BERT with a classifier\n",
        "- Train the new model, fine-tuning BERT as part of that\n",
        "- save model and use it to classify sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1242yQs2y5lf"
      },
      "source": [
        "###BERT\n",
        "In NLP, [BERT]() and other transformer encoder architectures have been widely successful. \n",
        "\n",
        "The BERT family of models uses the Transformer encoder architecture to process each token of input text in the full context of all tokens before and after, hence the name: Bidirectional Encoder Representations from Transformers.\n",
        "\n",
        "BERT models are usually pre_trained on a large corpus of text, then fine-tuned for specific tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1mHVN5Ez8Wy"
      },
      "source": [
        "###Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJQ0kGzOi-i6",
        "outputId": "d74007b3-093a-4b20-bef8-bbaa5e360ff5"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.3MB 31.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeLJ6HsX0jgH",
        "outputId": "79efce00-6ed1-4649-c43e-3f7391d150ec"
      },
      "source": [
        "!pip install -q tf-models-official"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6MB 19.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.2MB 82kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 37.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 41.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 42.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 52.0MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LVQrf3Y0sFu"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTaJG64a1LFn"
      },
      "source": [
        "###Sentiment Analysis\n",
        "we will train a sentiment analysis model to classify movie reviews as positive or negative, based on the text of the review.\n",
        "\n",
        "we will use the [Large Movie Review Dataset]() that contains the text of 50,000 movie reviews from the [Internet Movie Database]()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeevuCgG1JbP",
        "outputId": "993e576a-31f9-407c-9a86-5664f915d0b0"
      },
      "source": [
        "#Let's download and extract the dataset, then explore the directory structure.\n",
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url, \n",
        "                                  untar = True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "#Remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_yfjMve2viG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLnj94Jb2pGG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}